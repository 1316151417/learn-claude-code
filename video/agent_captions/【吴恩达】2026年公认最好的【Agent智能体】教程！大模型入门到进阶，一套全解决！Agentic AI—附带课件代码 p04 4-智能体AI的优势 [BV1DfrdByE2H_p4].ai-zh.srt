1
00:00:00,020 --> 00:00:03,020
我认为自主工作流最大的优势在于

2
00:00:03,020 --> 00:00:08,170
它能有效完成仅靠个人电脑无法实现的多项任务

3
00:00:08,170 --> 00:00:10,150
当然还有其他优势

4
00:00:10,150 --> 00:00:13,490
包括并行处理能力，能让某些任务快速完成

5
00:00:13,490 --> 00:00:17,270
以及模块化设计，可整合不同组件的最佳部分

6
00:00:17,270 --> 00:00:20,460
从多个来源构建高效工作流

7
00:00:20,460 --> 00:00:21,490
让我们看看具体案例

8
00:00:21,490 --> 00:00:25,490
我的团队收集了一些编码基准测试数据

9
00:00:25,490 --> 00:00:30,800
用于测试不同模型编写代码完成特定任务的能力

10
00:00:30,800 --> 00:00:33,960
这个基准测试称为Human Eval

11
00:00:33,960 --> 00:00:36,040
结果显示GPT-3.5

12
00:00:36,040 --> 00:00:40,280
这是首个公开版本的Chi GPU所基于的模型

13
00:00:40,280 --> 00:00:43,000
若直接要求它编写代码

14
00:00:43,000 --> 00:00:46,990
计算机程序在该基准测试中正确率仅40%

15
00:00:46,990 --> 00:00:48,530
这是Parse K指标

16
00:00:48,530 --> 00:00:50,230
GPT-4表现更优

17
00:00:50,230 --> 00:00:53,560
准确率跃升至67%

18
00:00:53,560 --> 00:00:55,980
即使使用非自主工作流

19
00:00:55,980 --> 00:00:59,200
但改进幅度如此之大

20
00:00:59,200 --> 00:01:01,740
从GPT-3.5到GPT-4

21
00:01:01,740 --> 00:01:05,540
这种提升可通过包装GPT-3.5

22
00:01:05,540 --> 00:01:10,650
并结合自主工作流技术实现

23
00:01:10,650 --> 00:01:11,610
这部分内容稍后会讲到

24
00:01:11,610 --> 00:01:12,190
在本课程中

25
00:01:12,190 --> 00:01:15,030
可提示GPT-3.5编写代码

26
00:01:15,030 --> 00:01:18,780
然后反思代码并优化改进

27
00:01:18,780 --> 00:01:20,240
通过这类技术

28
00:01:20,240 --> 00:01:24,580
实际上能让GPT-3.5达到更高性能

29
00:01:24,580 --> 00:01:30,890
同样GPT-4在自主工作流中表现更佳

30
00:01:30,890 --> 00:01:31,210
所以

31
00:01:31,210 --> 00:01:36,670
即使使用当今最佳语言模型

32
00:01:36,670 --> 00:01:42,739
自主工作流仍能显著提升性能

33
00:01:42,739 --> 00:01:44,960
事实上我们在此例中看到的

34
00:01:44,960 --> 00:01:49,680
模型迭代带来的改进

35
00:01:49,680 --> 00:01:55,479
仍不及在旧模型上应用自主工作流

36
00:01:55,479 --> 00:01:58,910
另一个优势是能并行处理任务

37
00:01:58,910 --> 00:01:59,690
从而比人类更快完成某些工作

38
00:01:59,690 --> 00:02:03,830
例如

39
00:02:03,830 --> 00:02:09,800
要求自主工作流撰写黑洞论文

40
00:02:09,800 --> 00:02:11,360
可同时运行三个模型生成搜索关键词

41
00:02:11,360 --> 00:02:12,760
输入搜索引擎

42
00:02:12,760 --> 00:02:13,920
基于首次搜索结果

43
00:02:13,920 --> 00:02:14,320
筛选出

44
00:02:14,320 --> 00:02:17,180
三个最佳结果

45
00:02:17,180 --> 00:02:22,180
根据第二次搜索识别第二组网页

46
00:02:22,180 --> 00:02:22,960
依此类推

47
00:02:22,960 --> 00:02:24,360
结果发现

48
00:02:24,360 --> 00:02:29,620
人类需按顺序阅读九个网页

49
00:02:29,620 --> 00:02:32,720
或逐一处理

50
00:02:32,720 --> 00:02:36,750
可并行下载所有九个网页

51
00:02:36,750 --> 00:02:40,230
然后最后将所有这些内容输入现在来撰写一篇论文

52
00:02:40,230 --> 00:02:45,650
因此尽管工作流确实比纯非生成式工作流耗时更长

53
00:02:45,650 --> 00:02:46,670
或者通过直接生成

54
00:02:46,670 --> 00:02:48,510
并且只需提示一次

55
00:02:48,510 --> 00:02:51,610
如果要比较这种生成式工作流

56
00:02:51,610 --> 00:02:54,030
与人类完成任务的方式

57
00:02:54,030 --> 00:02:55,550
瘫痪能力

58
00:02:55,550 --> 00:02:59,180
下载大量网页实际上可以让它完成某些任务

59
00:02:59,180 --> 00:03:05,880
比单个人类按顺序处理数据构建的方式快得多

60
00:03:05,880 --> 00:03:06,760
在这个示例中

61
00:03:06,760 --> 00:03:10,820
我发现构建工作流时经常做的一件事

62
00:03:10,820 --> 00:03:12,820
是查看各个组件

63
00:03:12,820 --> 00:03:16,560
比如语言模型并添加或替换组件

64
00:03:16,560 --> 00:03:17,810
例如

65
00:03:17,810 --> 00:03:20,490
我可能会检查这里使用的网络搜索引擎

66
00:03:20,490 --> 00:03:24,040
并决定替换为新的网络搜索引擎

67
00:03:24,040 --> 00:03:25,320
在构建通用工作流时

68
00:03:25,320 --> 00:03:27,140
实际上存在多个网络搜索引擎

69
00:03:27,140 --> 00:03:28,140
包括谷歌

70
00:03:28,140 --> 00:03:30,060
可通过Surper访问

71
00:03:30,060 --> 00:03:34,390
以及如必应、DuckDuckGo、TiYu.com等

72
00:03:34,390 --> 00:03:38,990
实际上有很多专为MS设计的网络搜索引擎选项

73
00:03:38,990 --> 00:03:41,570
或者除了进行三次网页搜索

74
00:03:41,570 --> 00:03:45,540
或许在此步骤可替换为新的新闻搜索引擎

75
00:03:45,540 --> 00:03:49,660
以便获取近期突破的最新新闻

76
00:03:49,660 --> 00:03:51,620
关于黑洞信号

77
00:03:51,620 --> 00:03:56,810
最后，不再使用同一语言模型处理所有步骤

78
00:03:56,810 --> 00:04:00,210
我通常会尝试不同的大型语言模型

79
00:04:00,210 --> 00:04:03,040
并尝试不同的模型提供商

80
00:04:03,040 --> 00:04:07,800
以观察哪个在系统不同步骤中效果最佳

81
00:04:07,800 --> 00:04:09,390
总结来说

82
00:04:09,390 --> 00:04:11,710
我使用生成式工作流的主要原因

83
00:04:11,710 --> 00:04:15,519
是显著提升多种应用的性能

84
00:04:15,519 --> 00:04:16,759
此外

85
00:04:16,759 --> 00:04:22,160
还能并行处理人类需按顺序完成的任务

86
00:04:22,160 --> 00:04:28,500
许多生成式工作流的模块化设计也允许我们添加更新工具

87
00:04:28,500 --> 00:04:30,700
有时替换模型

88
00:04:30,700 --> 00:04:34,900
我们将详细讨论构建工作流的关键组件

89
00:04:34,900 --> 00:04:38,860
现在让我们看看一系列AI应用

90
00:04:38,860 --> 00:04:42,240
让你了解人们已构建的类型

91
00:04:42,240 --> 00:04:44,970
以及你可以自行构建的类型

92
00:04:44,970 --> 00:04:47,040
我们进入下一视频

