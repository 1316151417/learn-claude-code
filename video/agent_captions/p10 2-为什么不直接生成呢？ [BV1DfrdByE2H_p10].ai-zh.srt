1
00:00:00,100 --> 00:00:03,600
让我们看看为什么我们可能更倾向于使用反射工作流

2
00:00:03,600 --> 00:00:08,029
而不是一次性提示并直接生成答案

3
00:00:08,029 --> 00:00:10,370
然后通过直接生成完成任务

4
00:00:10,370 --> 00:00:14,690
你只需向语言模型提供指令并让其生成答案

5
00:00:14,690 --> 00:00:19,860
所以当被要求写一篇关于黑洞的论文时，它会直接生成文本

6
00:00:19,860 --> 00:00:24,040
或者编写计算复利的Python函数

7
00:00:24,040 --> 00:00:25,880
然后直接输出代码

8
00:00:25,880 --> 00:00:31,250
这里看到的提示示例也被称为零样本提示

9
00:00:31,250 --> 00:00:33,480
让我解释什么是零样本

10
00:00:33,480 --> 00:00:35,760
与零样本提示相比

11
00:00:35,760 --> 00:00:39,920
相关的方法是包含一个或多个所需输出的示例

12
00:00:39,920 --> 00:00:41,900
在提示中展示期望的输出格式

13
00:00:41,900 --> 00:00:44,240
这种方法称为单样本提示

14
00:00:44,240 --> 00:00:45,140
如果在提示中

15
00:00:45,140 --> 00:00:50,120
包含一个所需输入输出对的示例，或双样本、多样本提示

16
00:00:50,120 --> 00:00:53,240
根据在提示中包含的示例数量

17
00:00:53,240 --> 00:00:57,100
因此零样本提示指的是不包含任何示例

18
00:00:57,100 --> 00:01:00,980
如果不包含任何所需输出的示例

19
00:01:00,980 --> 00:01:01,820
但不用担心

20
00:01:01,820 --> 00:01:03,880
如果你还不熟悉这些术语

21
00:01:03,880 --> 00:01:06,780
重要的是这里看到的示例

22
00:01:06,780 --> 00:01:10,890
你只需直接生成一个答案

23
00:01:10,890 --> 00:01:12,970
这也是我所说的零样本提示

24
00:01:12,970 --> 00:01:13,510
提示

25
00:01:13,510 --> 00:01:15,270
因为我们不包含任何示例

26
00:01:15,270 --> 00:01:21,200
多项研究表明反射能提升直接生成的性能

27
00:01:21,200 --> 00:01:23,230
在各种任务中

28
00:01:23,230 --> 00:01:28,480
此图改编自Madan等人的研究论文

29
00:01:28,480 --> 00:01:34,630
展示了不同模型和宽度下实现的不同任务

30
00:01:34,630 --> 00:01:35,910
在没有反射的情况下

31
00:01:35,910 --> 00:01:40,210
阅读此图需观察相邻的浅色条

32
00:01:40,210 --> 00:01:42,460
后跟深色条

33
00:01:42,460 --> 00:01:45,460
浅色条表示零样本提示

34
00:01:45,460 --> 00:01:48,500
深色条表示相同模型

35
00:01:48,500 --> 00:01:51,300
但使用反射，蓝色、绿色和红色表示不同模型实验

36
00:01:51,300 --> 00:01:55,100
如GPT-3.5和GPT-4

37
00:01:55,100 --> 00:01:56,180
以及GPT-3.5和GPT-4

38
00:01:56,180 --> 00:01:57,360
和GPT-4

39
00:01:57,360 --> 00:02:01,240
可以看到对于许多应用

40
00:02:01,240 --> 00:02:06,339
带有反射的深色条显著高于浅色条

41
00:02:06,339 --> 00:02:06,499
但

42
00:02:06,499 --> 00:02:10,158
当然具体应用的知识可能有所不同

43
00:02:10,158 --> 00:02:16,630
这里还有一些生成结构化数据时可能有帮助的例子

44
00:02:16,630 --> 00:02:18,170
例如HTML表格

45
00:02:18,170 --> 00:02:22,430
有时输出格式可能不正确

46
00:02:22,430 --> 00:02:26,260
因此验证模型代码的反射提示会很有帮助

47
00:02:26,260 --> 00:02:27,660
如果是基础HTML

48
00:02:27,660 --> 00:02:29,080
这可能帮助不大

49
00:02:29,080 --> 00:02:31,220
因为大多数模型已擅长基础HTML

50
00:02:31,220 --> 00:02:34,260
但尤其是对于更复杂的结构化输出

51
00:02:34,260 --> 00:02:37,160
可能像一个包含大量嵌套结构的JSON数据

52
00:02:37,160 --> 00:02:40,230
他们的感情可能更容易发现错误

53
00:02:40,230 --> 00:02:43,010
或者让你让模型生成步骤序列

54
00:02:43,010 --> 00:02:44,430
组成一组指令

55
00:02:44,430 --> 00:02:45,030
去做某件事

56
00:02:45,030 --> 00:02:47,420
例如如何冲泡一杯完美茶

57
00:02:47,420 --> 00:02:49,640
有时可能会漏掉步骤

58
00:02:49,640 --> 00:02:52,340
并使用反思提示让你检查指令

59
00:02:52,340 --> 00:02:55,190
确保连贯性和完整性可能有助于发现错误

60
00:02:55,190 --> 00:02:59,690
或者我实际做过的项目是用语言模型生成域名

61
00:02:59,690 --> 00:03:02,870
但生成的名称有时会有意外含义

62
00:03:02,870 --> 00:03:04,690
或者发音非常困难

63
00:03:04,690 --> 00:03:08,510
因此我使用反思提示双重检查域名

64
00:03:08,510 --> 00:03:11,460
是否有不当含义或问题

65
00:03:11,460 --> 00:03:13,460
或者名称是否难以发音

66
00:03:13,460 --> 00:03:16,140
我们团队确实使用过这个方法

67
00:03:16,140 --> 00:03:20,469
AI助手帮助初创公司 brainstorm 域名需求

68
00:03:20,469 --> 00:03:22,789
我想展示几个反思提示的例子

69
00:03:22,789 --> 00:03:24,900
用于 brainstorming 域名

70
00:03:24,900 --> 00:03:28,140
你可以让它审核你建议的域名

71
00:03:28,140 --> 00:03:30,850
然后检查每个名称是否易读

72
00:03:30,850 --> 00:03:34,410
检查名称在英语或其他语言中是否有负面含义

73
00:03:34,410 --> 00:03:38,870
然后输出符合这些标准的简短列表

74
00:03:38,870 --> 00:03:40,590
或优化一封邮件

75
00:03:40,590 --> 00:03:41,670
可以编写反思提示

76
00:03:41,670 --> 00:03:44,310
要求它先审阅邮件初稿

77
00:03:44,310 --> 00:03:45,130
检查语气

78
00:03:45,130 --> 00:03:46,230
验证所有事实

79
00:03:46,230 --> 00:03:47,660
确保声明和承诺准确

80
00:03:47,660 --> 00:03:50,200
这在模型上下文中会更合理

81
00:03:50,200 --> 00:03:53,120
因为已输入大量事实和日期等

82
00:03:53,120 --> 00:03:54,920
为了撰写邮件草稿

83
00:03:54,920 --> 00:03:58,149
所有内容将作为模型上下文提供

84
00:03:58,149 --> 00:04:00,089
然后根据发现的问题

85
00:04:00,089 --> 00:04:02,280
撰写邮件的下一稿

86
00:04:02,280 --> 00:04:03,440
编写反思提示的小技巧

87
00:04:03,440 --> 00:04:04,360
反思提示

88
00:04:04,360 --> 00:04:08,020
需明确指示要进行审阅

89
00:04:08,020 --> 00:04:11,730
或反思输出初稿

90
00:04:11,730 --> 00:04:14,200
如果能明确设定评估标准

91
00:04:14,200 --> 00:04:16,519
例如域名是否易读

92
00:04:16,519 --> 00:04:19,380
是否可能有负面含义或对邮件

93
00:04:19,380 --> 00:04:21,060
检查语气并验证事实

94
00:04:21,060 --> 00:04:24,580
这能更好地引导模型反思和批判

95
00:04:24,580 --> 00:04:27,350
针对你最关注的标准

96
00:04:27,350 --> 00:04:31,230
我发现提升提示写作的方法之一

97
00:04:31,230 --> 00:04:35,870
是大量阅读他人编写的提示

98
00:04:35,870 --> 00:04:40,789
有时我会下载开源软件并查找提示

99
00:04:40,789 --> 00:04:43,889
在某些特别优秀的软件中

100
00:04:43,889 --> 00:04:46,689
直接阅读作者编写的提示

101
00:04:46,689 --> 00:04:51,490
所以希望你能理解如何撰写一个基本的反思提示

102
00:04:51,490 --> 00:04:53,710
然后你甚至可以尝试在自己的工作中应用

103
00:04:53,710 --> 00:04:58,640
看看是否能帮助你在下一个视频中获得更好的表现

104
00:04:58,640 --> 00:05:00,620
我想和大家分享一个有趣的例子

105
00:05:00,620 --> 00:05:02,000
接下来我们将开始探讨

106
00:05:02,000 --> 00:05:05,190
多模态输入和输出将会

107
00:05:05,190 --> 00:05:10,190
算法会反思正在生成的图像或图表

108
00:05:10,190 --> 00:05:11,800
让我们一起去看看

